# 拦截恶意爬虫 {#concept_a4w_chl_q2b .concept}

当今互联网爬虫的种类繁多，本文介绍了如何使用WAF提供的各种功能来拦截恶意爬虫。

值得注意的是，为了绕过网站管理员的防爬策略，专业的爬虫往往会不断变换爬取手段，所以依靠固定的规则来实现一劳永逸的完美防护是不太可能的。此外，防爬往往与业务自身的特性有很强的关联，需要专业的安全团队进行对抗才能取得较好的效果。如果您对防爬效果有较高的要求，或者缺乏专业的安全团队来配置相应的安全策略，欢迎您扫描**文末**的钉钉二维码联系我们，帮助您定制防爬方案。

## 恶意爬虫的危害和特征 {#section_w5c_dhl_q2b .section}

正常爬虫通常会带有xxspider的user-agent标识，并且爬取的请求量不大，爬取URL和时间段都比较分散。合法的爬虫IP在做反向的nslookup或tracert时，一般都可以看到合法的来源地址。例如，下图显示了一条百度爬虫的记录。

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/15615/15331812888008_zh-CN.png)

而恶意爬虫可能会在某个时间段大量请求某个域名的特定地址/接口，这很可能是伪装成爬虫的CC攻击，或是经第三方伪装后，针对性爬取敏感信息的请求。当恶意爬虫请求量大到一定程度，往往可以造成服务器的CPU飙升，带来网站无法打开等业务中断问题。

WAF会针对恶意爬虫进行[风险预警](../../../../intl.zh-CN/用户指南/防护统计/风险预警报表.md#)，提示用户昨日爬虫的请求情况。您可以结合具体的业务情况，有针对性地配置下列规则中的一种或几种，来拦截对应的爬虫请求。

## 配置精准访问控制拦截特定爬虫 {#section_y5c_dhl_q2b .section}

通过[配置精准访问控制规则](../../../../intl.zh-CN/用户指南/防护配置/精准访问控制.md#)，您可以灵活地结合user-agent和URL等关键字段来过滤恶意爬虫请求。例如，使用下面的配置，可以只放行百度爬虫，而过滤其他的爬虫（关键字对大小写不敏感）。

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/15615/15331812888009_zh-CN.png)

**说明：** 同一条规则中的多个条件之间为“与”的关系，即必须同时满足所有条件，该条规则才会生效。

使用下面的配置，可以禁止任何爬虫访问/userinfo目录下的所有内容。

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/15615/15331812888010_zh-CN.png)

## 配置自定义CC规则拦截恶意请求 {#section_bvc_dhl_q2b .section}

使用[自定义CC规则](../../../../intl.zh-CN/用户指南/防护配置/自定义CC防护.md#)，可针对特定的路径配置访问频率的检测和阻断规则。

## 配置数据风控拦截恶意请求 {#section_cvc_dhl_q2b .section}

[数据风控](../../../../intl.zh-CN/用户指南/防护配置/数据风控.md#)可基于人机识别和大数据等技术对特定接口（如登录、注册、短信验证码、投票、下单、抢购等）或目录（如房产信息、用户信息等）做防护。

## 配置区域封禁拦截恶意请求 {#section_dvc_dhl_q2b .section}

如果恶意请求大量来自于特定区域（如海外），且正常的业务访问都没有该区域的请求，则可以开启[区域封禁](../../../../intl.zh-CN/用户指南/防护配置/封禁地区.md#)来拦截这种请求。

